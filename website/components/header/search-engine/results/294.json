{"type":"doc","filename":"devonfw-guide_devon4net.wiki_howto.asciidoc.html","anchor":"devonfw-guide_devon4net.wiki_howto.asciidoc_how-to-kafka","title":"How to: Kafka","breadcrumbs":[".net","How To section","How to use devon4net"],"text":"How to: Kafka\n\nIn this part of the document you will learn how to use kafka component and create and use Producers and Consumers for your application. You will also learn to use the different Handlers available in the Devon4Net.Infrastructure.Kafka component and how to configure them.\n\n\nPrevious steps\n\nTo use Kafka you need to have an active Kafka server. There are multple ways to use a kafka server, we are using a docker image but you can choose any desired form.\n\n\n\n\n\nNote\n\n\nWe recommend you to go through Kafka Documentation to learn how to get started with Apache Kafka.\n\n\n\n\n\nOnce you have an Apache Kafka Server up and running you will need to create a project using the Devon4Net template or add Devon4Net.Infrastructure.Kafka NuGet package reference to your project.\n\n\n\n\n\nNote\n\n\nYou can learn how to set up the component in your project by reading the component documentation.\n\n\n\n\n\n\nConfiguration\n\nWhen you have both things ready, you can start by adding the following line in your Program.cs\n\n\n\n\n\n\n\nNow is the time to configure all the producers and consumers you will be using in the application. You will later be relating this configuration to the Consumer and Producer Handler classes. For that you will need to complete the following configuration in appsettings.{environment}.json file with your preferred parameters.\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nPlease refer to the component documentation to learn more about the configuration.\n\n\n\n\n\n\nProducer\n\nAfter defining the configuration in the appsettings.{environment}.json now you can create your handlers extending the ones available in the Kafka component.\n\n\nFor the producer you can do something as the following:\n\n\n\n\n\n\n\nYou will need to add this handler to your dependencies. For that you can use the following method, and include the Id of the configuration as a parameter:\n\n\n\n\n\n\n\nNow you can use the handler in any constructor via dependency injection:\n\n\n\n\n\n\n\nFor example, in the previous piece of code, you can see how we are delivering a message to the Kafka server using a POST method in our API. This is done thanks to the SendMessage method.\n\n\n\nConsumer\n\nThe consumer is a little different, as you can see in the following piece of code, you will need to override the HandleCommand method. This will handle the process of consuming new messages to which the consumer is subscribed.\n\n\n\n\n\n\n\nSimilar to the producer, the Consumer also needs to be related to a configuration via the Id as follows:\n\n\n\n\n\n\n\n\nStream\n\nTo create a stream with some logic on it you will need to create a service that extends the class KafkaStreamService&lt;KeyType, ValueType&gt; and override its method CreateStreamBuilder with something as follows:\n\n\n\n\n\n\n\nThe StreamBuilder will allow you to add all the logic to the stream. You can check Streamiz Docs to learn about the Stateless and Statefull Processors available on Kafka Streams.\n\n\nIn the example, the Stream&lt;&gt;() method will create a Stream for the topic \"message_producer\". Inside this stream, the method Peek will do some operations based on the input data and return the input stream as-is, allowing to add more logic to it. In this case we use it to take a look to what is happening inside the stream.\n\n\nThen the method To will output the messages processed to another Stream, in this case \"message_consumer\".\n\n\n\n\n\n\n\n\nSerialization\n\nKafka works with byte arrays so we need to serialize the data before sending it and deserializing after receiving.\n\n\nThe process of turning objects into bytes is called serialization. The opposite procedure, known as deserialization, transforms a stream of bytes into an object.\n\n\nIn devon4net, we provide default serializers for basic types and a default one for serializing custom objects. However, you can specify your own custom ones.\n\n\nProducer\n\nThe Producer will need to know how to serialize both, the key and the value data into bytes. So you will need to create a class that implements the interface ISerializer&lt;T&gt; from the package Confluent.Kafka. For example:\n\n\n\n\n\n\n\nThen you can indicate the use of this serializer for the value in your Program.cs, as follows:\n\n\n\n\n\n\n\n\nConsumer\n\nThe Producer will need to know how to deserialize both, the key and the value bytes to readable data. So you will need to create a class that implements the interface IDeserializer&lt;T&gt; from the package Confluent.Kafka. For example:\n\n\n\n\n\n\n\nThen you can indicate the use of this deserializer for the key in your Program.cs, as follows:\n\n\n\n\n\n\n\n\nStream\n\nOn the other hand, as the stream is located between the producer and the consumer, it will need both to serialize and deserialize, also the key and the value. For the stream, you will need to create a class that implements the interface ISerDes&lt;T&gt; from the package Streamiz.Kafka.Net.SerDes. For example:\n\n\n\n\n\n\n\nThen you can indicate the use of this \"SerDes\" in your Program.cs, as follows:\n\n\n\n\n\n\n\n\n\n\n"}