{"type":"solution","filename":"microservices_azure_aks/index.asciidoc","title":"Microservice Platforms Solutions - Azure Kubernetes Service","breadcrumbs":[],"text":"//Category=Microservice Platforms;Kubernetes\n//Product=Azure Kubernetes Service;Azure Container Instances;Azure Red Hat OpenShift\n//Platform=Azure\n//Maturity level=Complete\n\n:toc: macro\ntoc::[]\n:idprefix:\n:idseparator: -\n\n= Microservice Platforms Solutions - Azure Kubernetes Service\n\ninclude::/home/runner/work/devonfw.github.io/devonfw.github.io/solutions/includes/microservices_problem/index.asciidoc[]\n\ninclude::/home/runner/work/devonfw.github.io/devonfw.github.io/solutions/includes/microservices_platforms/index.asciidoc[]\n\n== Microservice Platforms Solutions - Azure Kubernetes Service\n=== Infrastructure\n==== Overview\n\nThe solution is to use Azure Kubernetes Service and the following platform features regarding. The focus of this chapter is to introduce the relevant features. Recommendations for a concrete setup are given in the next chapter.\nThe platform features that (can) complement Kubernetes are:\n\nThe services that (can) complement Kubernetes:\n\n* Advisory\n+\n--\nProactive and actionable recommendations from Azure Advisor based on your configuration and usage telemetry as described here.\n--\n* Provisioning\n+\n--\nUse Bridge to Kubernetes to iteratively develop, test, and debug microservices targeted for AKS clusters. It is a https://azure.microsoft.com/de-de/updates/azure-dev-spaces-is-retiring-on-31-october-2023/[client-only experience] offered through extensions in Visual Studio and Visual Studio Code. See also Provisioning for general aspects and service options for creating pipelines for creating infrastructure.\n--\n* Compliance\n+\n--\nUse security measures on networking level to avoid public IPs. Combine AKS with additional services to control ingress and outgoing traffic such as Application Gateway or firewalls.\n\nEnforce compliance rules to your cluster and CI/CD pipeline consistently with Azure Policy. Azure Active Directory provides access control with role-based-access-controls (RBAC) and service principals/ managed identities to back RBAC roles. Integration with Azure Security Center can provide security management, intelligent threat detection and actionable recommendations. \n--\n* Desaster recovery\n+\n--\nHigher availability using redundancies across availability zones, protecting applications from datacenter failures. Paired region deployment for disaster recovery.\n--\n* Monitoring\n+\n--\nFor infrastructure monitoring see \"Monitoring\". For infrastructure monitoring specific pages in Azure Monitor exist which will be described here.\n--\n\nThe picture below summarizes some of the services mentioned above:\n\nimage::aks_overview.png[AKS Overview, width=794, height=568]\n\n[.internal]\nsolution_microservices_azure_aks_infra_detailed_native_setup\n\n=== Application\n==== Overview\n\nThe solution is to deploy the containerized application to an Azure Kubernetes Service. Focus of that chapter are designing, building, monitoring and deploying containerized applications. Recommendations for a concrete setup are given in the next chapter.\n\nThe services that (can) complement Kubernetes:\n\n* Designing\n+\n--\nEach Pod is meant to run a single instance of a given application. If you want to scale your application horizontally (to provide more overall resources by running more instances), you should use multiple Pods, one for each instance. In Kubernetes, this is typically referred to as replication. Replicated Pods are usually created and managed as a group by a workload resource and its controller.\n\nThe \"one-container-per-Pod\" model is the most common Kubernetes use case. A more advanced use case is running multiple containers in a pod that need to work together. A Pod can encapsulate an application composed of multiple co-located containers that are tightly coupled and need to share resources. These co-located containers form a single cohesive unit of service - for example, one container serving data stored in a shared volume to the public, while a separate sidecar container refreshes or updates those files. The Pod wraps these containers, storage resources, and an ephemeral network identity together as a single unit.\n\nContainers have to store information persistently. https://docs.microsoft.com/en-us/azure/aks/concepts-storage[Azure] provides Azure (managed) disks and Azure files as storage options for persistent volumes.\nAKS can connect with databases via wrapper objects such as Services  or databases can be directly deployed to Kubernetes. Options for deplyong a database directly to Kubernetes are given below:\n\n** SQL server (Microsoft): Options range from single https://docs.microsoft.com/en-us/sql/linux/tutorial-sql-server-containers-kubernetes?view=sql-server-ver15[sql server] to https://docs.microsoft.com/en-us/sql/linux/tutorial-sql-server-containers-kubernetes-dh2i?view=sql-server-ver15[high availability] with failover groups. In both cases MS provides containers that contain sql server.\n** Third party options such as https://portworx.com/blog/ha-postgresql-azure-aks/[PostgreSQL]\n--\n* Configuration\n+\n--\nConfigmaps are useful to store non-critical data in key-value pair format. They can also be used to inject env vars into pods. Secrets are useful to store sensitive data in key value pair format. They can also be used to inject env vars into pods. You can optionally specify how much of each resource a container needs. The most common resources to specify are CPU and memory (RAM).\n--\n* Compliance\n+\n--\nA https://kubernetes.io/docs/tasks/configure-pod-container/security-context/[security context] defines privilege and access control settings for a pod. Examples are: \n\n** Discretionary Access Control: Permission to access an object, like a file, is based on user ID (UID) and group ID (GID).\n** Security Enhanced Linux (SELinux): Objects are assigned security labels.\n** Running as privileged or unprivileged.\n** Linux Capabilities: Give a process some privileges, but not all the privileges of the root user.\n** AppArmor: Use program profiles to restrict the capabilities of individual programs.\n** AllowPrivilegeEscalation: Controls whether a process can gain more privileges than its parent process.\n** readOnlyRootFilesystem: Mounts the container's root filesystem as read-only.\n\nDisks used in your AKS cluster can by encrypted by using your own keys through Azure Key Vault.\n\nSee building for additional security measures when containers are built.\n--\n* Building (CI part of provisioning)\n+\n--\nBuilding containers includes the following steps:\n\n1. Building the container image(s)\n2. Pushing the image(s) to the registry\n\nProvisioning tools such as Azure DevOps and Gitub Actions provide special docker tasks/ activities to build images. Pushing to registries is also supported. The following additional features can be used/ should be considered from security perspective:\n\n** Each time a *base image is updated*, you should also update any downstream container images. Integrate this build process into validation and deployment pipelines such as Azure Pipelines or Jenkins. These pipelines make sure that your applications continue to run on the updated based images. Once your application container images are validated, the AKS deployments can then be updated to run the latest, secure images. Azure Container Registry Tasks can also https://docs.microsoft.com/en-us/azure/aks/operator-best-practices-container-image-management[automatically update container images] when the base image is updated.\n**  https://docs.microsoft.com/en-us/azure/aks/operator-best-practices-container-image-management[A container security scan] can be included in the *pipelines as quality gate* by using tools like tools such as Twistlock or Aqua.\n** The https://docs.microsoft.com/en-us/azure/devops/pipelines/ecosystems/containers/content-trust?view=azure-devops[provisioning services support] Docker Content Trust (DCT). Docker Content Trust (DCT) are digital signatures for data sent to and received from remote Docker registries. These signatures allow client-side or runtime verification of the integrity and publisher of specific image tags.\n--\n* Deployment (CI part of provisioning)\n+\n--\nThe term \"Deployment\" refers to the process that triggers a deployment in Kubernetes whereas a Kubernetes deployment refers to the Kubernets deployment resource. A kubernetes deployment resource is the standard controller for manipulating pods which in turn host the container workloads.\n\nA deployment is triggered by the provisioning pipeline.  Depending on the scope a deployment goes beyond the a kubernetes deployment that results in a Kubernetes deployment resource. The various steps across various scenarios can be generalized as follows:\n\n1. Pre-Kubernetes Deployment steps\n2. Kubernetes Deployment\nAzure provisioning services provide ways to trigger with native kubernetes means such as manifests by supporting special tasks/ activties. However, this results in quite a number of files you have to maintain. Additional tools like https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/deploy/helm-deploy?view=azure-devops[helm] (see variation) provide better support.\n3. Post-Kubernetes Deployment steps\n\nThe most complex deployment scenario is a rolling update with breaking database changes. In that case pre and post Kubernetes deployment steps are required to https://stackoverflow.com/questions/48877182/kubernetes-rolling-deployments-and-database-migrations/48880687[handle the breaking database changes]. Such an update requires targeting specific components e.g. with a certain version. Labels are key/value pairs that are attached to objects, such as pods. They help in filtering out specific objects. Using a Selector, the client/user can identify a set of objects. Annotations are used to attach arbitrary non-identifying metadata to objects.\n\nThe basic idea is to break down the breaking database change into multiple non-breaking steps. The https://stackoverflow.com/questions/48877182/kubernetes-rolling-deployments-and-database-migrations/48880687[steps below] refer to a renaming of a column:\n\n1. Add a db migration that inserts the new column\n2. Change the app so that all writes go to the old and new column\n3. Run a task that copies all values from the old to the new column\n4. Change the app that it reads from the new column\n5. Add a migration that remove the old column\n--\n* Monitoring\n+\n--\nApplication logs can help in understanding the activities and status of the application. The logs are particularly useful for debugging problems and monitoring cluster activity. Monitoring applications can be done by storing logs and studying the application’s metrics.\n\nTools like Prometheus-Grafana are popular as they make the management of metrics very easy. Very often, sidecar containers are used as metrics exporters of the main application container.\n\nBy https://docs.microsoft.com/en-us/azure/azure-monitor/containers/container-insights-prometheus-integration[integrating with Azure Monitor], a Prometheus server is not required. You just need to expose the Prometheus metrics endpoint through your exporters or pods (application), and the containerized agent for Container insights can scrape the metrics for you.\n\nimage::mon_cnt_insights.png[alt=Monitoring Container Insights,width=1706, height=632]\n--\n\n==== Variations\n\nThe following additional extra tools can be used in conjunction with Kubernetes:\n\n* Deployment\n+\n--\nInstead of having to write separate YAML files for each application manually, you can simply create a Helm chart and let Helm deploy the application to the cluster for you. Helm charts contain templates for various Kubernetes resources that combine to form an application. \n\nimage::helm_chart_example.png[alt=Helm chart example]\n\nA Helm chart can be customized when deploying it on different Kubernetes clusters. Helm charts can be created in such a way that environment or deployment-specific configurations can be extracted out to a separate file so that these values can be specified when the Helm chart is deployed. The snippet below shows a template using placeholders to refer to the values in values.yaml:\n```YAML\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: {{ .Values.postgres.name }}\n  labels:\n    app: {{ .Values.postgres.name }}\n    group: {{ .Values.postgres.group }}\nspec:\n  replicas: {{ .Values.replicaCount }}\n  selector:\n    matchLabels:\n      app: {{ .Values.postgres.name }}\n      ...\n```\n\n--\n* Compliance\n+\n--\nFor security reasons and improvement of Helm charts, it is useful to make use of at least one Helm linting tool to ensure your deployments are valid and versioned correctly.\n\nWhy choosing Polaris as Linting Tool: For helm chart linting, there are several tools like Polaris, kube-score or config-lint available. With Polaris, checks and rules are already given by default, whereby other tools need a lot of custom rules configuration and are therefore more complex to setup. Polaris runs a variety of checks to ensure that Kubernetes pods and controllers are configured using best practices, helping to avoid problems in the future. Polaris can be either installed inside a cluster or as a command-line tool to analyze Kubernetes manifests statically.\n--\n* Configuration\n+\n--\nSee under infrastructure.\n--\n\n==== When to use\n\nWhen you want to deploy containerized applications to Azure Kubernetes Service.\n\n== Credits\n\nimage::ms_guild_logo.png[MS Guild Logo, width=160, height=75, align=right, link=\"https://forms.office.com/Pages/ResponsePage.aspx?id=Wq6idgCfa0-V7V0z13xNYal7m2EdcFdNsyBBMUiro4NUNllHQTlPNU9QV1JRRjk3TTAwVUJCNThTRSQlQCN0PWcu\"]\n"}